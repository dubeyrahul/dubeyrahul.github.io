---
toc: False
title: Title

keywords: fastai
sidebar: home_sidebar

summary: "Awesome summary"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-01-29-dummy-notebook.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can read an overview of this Numerical Linear Algebra course in <a href="http://www.fast.ai/2017/07/17/num-lin-alg/">this blog post</a>.  The course was originally taught in the <a href="https://www.usfca.edu/arts-sciences/graduate-programs/analytics">University of San Francisco MS in Analytics</a> graduate program.  Course lecture videos are <a href="https://www.youtube.com/playlist?list=PLtmWHNX-gukIc92m1K0P6bIOnZb-mg0hY">available on YouTube</a> (note that the notebook numbers and video numbers do not line up, since some notebooks took longer than 1 video to cover).</p>
<p>You can ask questions about the course on <a href="http://forums.fast.ai/c/lin-alg">our fast.ai forums</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="1.-Why-are-we-here?">1. Why are we here?<a class="anchor-link" href="#1.-Why-are-we-here?">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Note: Future lessons have a lot more code than this one</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Why-study-Numerical-Linear-Algebra?">Why study Numerical Linear Algebra?<a class="anchor-link" href="#Why-study-Numerical-Linear-Algebra?">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Key Question of this course</strong>: How can we do matrix computations with acceptable speed and acceptable accuracy?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are 4 things to keep in mind when choosing or designing an algorithm for matrix computations:</p>
<ul>
<li>Memory Use</li>
<li>Speed</li>
<li>Accuracy</li>
<li>Scalability/Parallelization</li>
</ul>
<p>Often there will be trade-offs between these categories.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Motivation">Motivation<a class="anchor-link" href="#Motivation">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Matrices are everywhere-- anything that can be put in an Excel spreadsheet is a matrix, and language and pictures can be represented as matrices as well.  Knowing what options there are for matrix algorithms, and how to navigate compromises, can make enormous differences to your solutions. For instance, an approximate matrix computation can often be thousands of times faster than an exact one.</p>
<p>It's not just about knowing the contents of existing libraries, but knowing how they work too. That's because often you can make variations to an algorithm that aren't supported by your library, giving you the performance or accuracy that you need. In addition, this field is moving very quickly at the moment, particularly in areas related to <strong>deep learning</strong>, <strong>recommendation systems</strong>, <strong>approximate algorithms</strong>, and <strong>graph analytics</strong>, so you'll often find there's recent results that could make big differences in your project, but aren't in your library.</p>
<p>Knowing how the algorithms really work helps to both debug and accelerate your solution.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Matrix-Computations">Matrix Computations<a class="anchor-link" href="#Matrix-Computations">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are two key types of matrix computation, which get combined in many different ways. These are:</p>
<ul>
<li>Matrix and tensor products</li>
<li>Matrix decompositions</li>
</ul>
<p>So basically we're going to be combining matrices, and pulling them apart again!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Matrix-and-Tensor-Products">Matrix and Tensor Products<a class="anchor-link" href="#Matrix-and-Tensor-Products">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Matrix-Vector-Products:">Matrix-Vector Products:<a class="anchor-link" href="#Matrix-Vector-Products:">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The matrix below gives the probabilities of moving from 1 health state to another in 1 year.  If the current health states for a group are:</p>
<ul>
<li>85% asymptomatic</li>
<li>10% symptomatic</li>
<li>5% AIDS</li>
<li>0% death</li>
</ul>
<p>what will be the % in each health state in 1 year?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Answer">Answer<a class="anchor-link" href="#Answer">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#Exercise: Use Numpy to compute the answer to the above</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[ 0.765 ],
       [ 0.1525],
       [ 0.0645],
       [ 0.018 ]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Matrix-Matrix-Products">Matrix-Matrix Products<a class="anchor-link" href="#Matrix-Matrix-Products">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Only after you've written down what you think the answer should be, run the code below:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">80</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>What went wrong?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Problem:-math-is-continuous-&amp;-infinite,-but-computers-are-discrete-&amp;-finite">Problem: math is continuous &amp; infinite, but computers are discrete &amp; finite<a class="anchor-link" href="#Problem:-math-is-continuous-&amp;-infinite,-but-computers-are-discrete-&amp;-finite">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Two Limitations of computer representations of numbers:</p>
<ol>
<li>they can't be arbitrarily large or small</li>
<li>there must be gaps between them</li>
</ol>
<p>The reason we need to care about accuracy, is because computers can't store infinitely accurate numbers.  It's possible to create calculations that give very wrong answers (particularly when repeating an operation many times, since each operation could multiply the error).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>IEEE Double precision arithmetic:</p>
<ul>
<li>Numbers can be as large as $1.79 \times 10^{308}$ and as small as $2.23 \times 10^{-308}$.</li>
<li><p>The interval $[1,2]$ is represented by discrete subset: 
$$1, \: 1+2^{-52}, \: 1+2 \times 2^{-52},\: 1+3 \times 2^{-52},\: \ldots, 2$$</p>
</li>
<li><p>The interval $[2,4]$ is represented:
$$2, \: 2+2^{-51}, \: 2+2 \times 2^{-51},\: 2+3 \times 2^{-51},\: \ldots, 4$$</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Machine Epsilon</strong></p>
<p>Half the distance between 1 and the next larger number. This can vary by computer.  IEEE standards for double precision specify $$ \varepsilon_{machine} = 2^{-53} \approx 1.11 \times 10^{-16}$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Two important properties of Floating Point Arithmetic</strong>:</p>
<ul>
<li><p>The difference between a real number $x$ and its closest floating point approximation $fl(x)$ is always smaller than $\varepsilon_{machine}$ in relative terms.  For some $\varepsilon$, where $\lvert \varepsilon \rvert \leq \varepsilon_{machine}$, $$fl(x)=x \cdot (1 + \varepsilon)$$</p>
</li>
<li><p>Where <em> is any operation ($+, -, \times, \div$), and $\circledast$ is its floating point analogue,
  $$ x \circledast y = (x </em> y)(1 + \varepsilon)$$
for some $\varepsilon$, where $\lvert \varepsilon \rvert \leq \varepsilon<em>{machine}$
That is, every operation of floating point arithmetic is exact up to a relative error of size at most $\varepsilon</em>{machine}$</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="History">History<a class="anchor-link" href="#History">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Floating point arithmetic may seem like a clear choice in hindsight, but there have been many, many ways of storing numbers:</p>
<ul>
<li>fixed-point arithmetic</li>
<li>logarithmic and semilogarithmic number systems</li>
<li>continued-fractions</li>
<li>rational numbers</li>
<li>possibly infinite strings of rational numbers</li>
<li>level-index number systems</li>
<li>fixed-slash and floating-slash number systems</li>
<li>2-adic numbers</li>
</ul>
<p>For references, see <a href="https://perso.ens-lyon.fr/jean-michel.muller/chapitre1.pdf">Chapter 1</a> (which is free) of the <a href="http://www.springer.com/gp/book/9780817647049">Handbook of Floating-Point Arithmetic</a>.  Yes, there is an entire 16 chapter book on floating point!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Timeline History of Floating Point Arithmetic:</p>
<ul>
<li>~1600 BC: Babylonian radix-60 system was earliest floating-point system (Donald Knuth).  Represented the significand of a radix-60 floating-point representation (if ratio of two numbers is a power of 60, represented the same)</li>
<li>1630 Slide rule.  Manipulate only significands (radix-10)</li>
<li>1914 Leonardo Torres y Quevedo described an electromechanical implementation of Babbage's Analytical Engine with Floating Point Arithmetic.</li>
<li>1941 First real, modern implementation.  Konrad Zuse's Z3 computer.  Used radix-2, with 14 bit significand, 7 bit exponents, and 1 sign bit.</li>
<li>1985 IEEE 754-1985 Standard for Binary Floating-Point Arithmetic released.  Has increased accuracy, reliability, and portability.  <a href="https://people.eecs.berkeley.edu/~wkahan/">William Kahan</a> played leading role.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>"Many different ways of approximating real numbers on computers have been introduced.. And yet, floating-point arithmetic is <strong>by far the most widely used</strong> way of representing real numbers in modern computers. Simulating an infinite, continuous set (the real numbers) with a finite set (the “machine numbers”) is not a straightforward task: <strong>clever compromises must be found between, speed, accuracy, dynamic range, ease of use and implementation, and memory</strong>. It appears that floating-point arithmetic, with adequately chosen parameters (radix, precision, extremal exponents, etc.), is a very good compromise for most numerical applications."</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Although a radix value of 2 (binary) seems like the pretty clear winner now for computers, a variety of other radix values have been used at various point:</p>
<ul>
<li>radix-8 used by early machines PDP-10, Burroughs 570 and 6700</li>
<li>radix-16 IBM 360</li>
<li>radix-10 financial calculations, pocket calculators, Maple</li>
<li>radix-3 Russian SETUN computer (1958).  Benefits: minimizes beta x p (symbols x digits), for a fixed largest representable number beta^p - 1.  Rounding = truncation</li>
<li>radix-2 most common.  Reasons: easy to implement.  Studies have shown (with implicit leading bit) this gives better worst-case or average accuracy than all other radices.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Conditioning-and-Stability">Conditioning and Stability<a class="anchor-link" href="#Conditioning-and-Stability">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since we can not represent numbers exactly on a computer (due to the finiteness of our storage, and the gaps between numbers in floating point architecture), it becomes important to know <em>how small perturbations in the input to a problem impact the output</em>.</p>
<p><strong>"A stable algorithm gives nearly the right answer to nearly the right question."</strong> --Trefethen</p>
<p><strong>Conditioning</strong>: perturbation behavior of a mathematical problem (e.g. least squares)</p>
<p><strong>Stability</strong>: perturbation behavior of an algorithm used to solve that problem on a computer (e.g. least squares algorithms, householder, back substitution, gaussian elimination)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Example: Eigenvalues of a Matrix</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.linalg</span> <span class="k">as</span> <span class="nn">la</span> 

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[    1.  1000.]
 [    0.     1.]]
[[    1.     1000.   ]
 [    0.001     1.   ]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">wA</span><span class="p">,</span> <span class="n">vrA</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">wB</span><span class="p">,</span> <span class="n">vrB</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>

<span class="n">wA</span><span class="p">,</span> <span class="n">wB</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Reminder: Two properties of Floating Point Arithmetic</strong></p>
<ul>
<li><p>The difference between a real number $x$ and its closest floating point approximation $fl(x)$ is always smaller than $\varepsilon_{machine}$ in relative terms.</p>
</li>
<li><p>Every operation $+, -, \times, \div$ of floating point arithmetic is exact up to a relative error of size at most $\varepsilon_{machine}$</p>
</li>
</ul>
<p>Examples we'll see:</p>
<ul>
<li>Classical vs Modified Gram-Schmidt accuracy</li>
<li>Gram-Schmidt vs. Householder (2 different ways of computing QR factorization), how orthogonal the answer is</li>
<li>Condition of a system of equations</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Approximation-accuracy">Approximation accuracy<a class="anchor-link" href="#Approximation-accuracy">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Expensive-Errors">Expensive Errors<a class="anchor-link" href="#Expensive-Errors">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>The below examples are from Greenbaum &amp; Chartier.</em></p>
<p>European Space Agency spent 10 years and $7 billion on the Ariane 5 Rocket.</p>
<p>What can happen when you try to fit a 64 bit number into a 16 bit space (integer overflow):</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s2">&quot;PK_yguLapgA&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

        <iframe
            width="400"
            height="300"
            src="https://www.youtube.com/embed/PK_yguLapgA"
            frameborder="0"
            allowfullscreen
        ></iframe>
        
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here is a floating point error that cost Intel $475 million:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Resources</strong>: See Lecture 13 of Trefethen &amp; Bau and Chapter 5 of Greenbaum &amp; Chartier for more on Floating Point Arithmetic</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Memory-Use">Memory Use<a class="anchor-link" href="#Memory-Use">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Sparse-vs-Dense">Sparse vs Dense<a class="anchor-link" href="#Sparse-vs-Dense">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Speed">Speed<a class="anchor-link" href="#Speed">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Speed differences come from a number of areas, particularly:</p>
<ul>
<li>Computational complexity</li>
<li>Vectorization</li>
<li>Scaling to multiple cores and nodes</li>
<li>Locality</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Computational-complexity">Computational complexity<a class="anchor-link" href="#Computational-complexity">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you are unfamiliar with computational complexity and $\mathcal{O}$ notation, you can read about it <a href="https://www.interviewcake.com/article/java/big-o-notation-time-and-space-complexity">on Interview Cake</a> and <a href="https://www.codecademy.com/courses/big-o/0/3">practice on Codecademy</a>. Algorithms are generally expressed in terms of computation complexity with respect to the number of rows and number of columns in the matrix. E.g. you may find an algorithm described as $\mathcal{O(n^2m)}$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Vectorization">Vectorization<a class="anchor-link" href="#Vectorization">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Modern CPUs and GPUs can apply an operation to multiple elements at once on a single core. For instance, take the exponent of 4 floats in a vector in a single step. This is called SIMD. You will not be explicitly writing SIMD code (which tends to require assembly language or special C "intrinsics"), but instead will use vectorized operations in libraries like numpy, which in turn rely on specially tuned vectorized low level linear algebra APIs (in particular, BLAS, and LAPACK).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Matrix-Computation-Packages:-BLAS-and-LAPACK">Matrix Computation Packages: BLAS and LAPACK<a class="anchor-link" href="#Matrix-Computation-Packages:-BLAS-and-LAPACK">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="http://www.netlib.org/blas/">BLAS (Basic Linear Algebra Subprograms)</a>: specification for low-level matrix and vector arithmetic operations. These are the standard building blocks for performing basic vector and matrix operations.  BLAS originated as a Fortran library in 1979.  Examples of BLAS libraries include: AMD Core Math Library (ACML), ATLAS, Intel Math Kernel Library (MKL), and OpenBLAS.</p>
<p><a href="http://www.netlib.org/lapack/">LAPACK</a> is written in Fortran, provides routines for solving systems of linear equations, eigenvalue problems, and singular value problems.  Matrix factorizations (LU, Cholesky, QR, SVD, Schur).  Dense and banded matrices are handled, but not general sparse matrices.  Real and complex, single and double precision.</p>
<p>1970s and 1980s: EISPACK (eigenvalue routines) and LINPACK (linear equations and linear least-squares routines) libraries</p>
<p><strong>LAPACK original goal</strong>: make LINAPCK and EISPACK run efficiently on shared-memory vector and parallel processors and exploit cache on modern cache-based architectures (initially released in 1992).  EISPACK and LINPACK ignore multi-layered memory hierarchies and spend too much time moving data around.</p>
<p>LAPACK uses highly optimized block operations implementations (which much be implemented on each machine) LAPACK written so as much of the computation as possible is performed by BLAS.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Locality">Locality<a class="anchor-link" href="#Locality">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using slower ways to access data (e.g. over the internet) can be up to a billion times slower than faster ways (e.g. from a register). But there's much less fast storage than slow storage. So once we have data in fast storage, we want to do any computation required at that time, rather than having to load it multiple times each time we need it. In addition, for most types of storage its much faster to access data items that are stored next to each other, so we should try to always use any data stored nearby that we know we'll need soon. These two issues are known as locality.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Speed-of-different-types-of-memory">Speed of different types of memory<a class="anchor-link" href="#Speed-of-different-types-of-memory">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here are some <em>numbers everyone should know</em> (from the legendary <a href="http://static.googleusercontent.com/media/research.google.com/en/us/people/jeff/stanford-295-talk.pdf">Jeff Dean</a>):</p>
<ul>
<li>L1 cache reference 0.5 ns</li>
<li>L2 cache reference 7 ns</li>
<li>Main memory reference/RAM 100 ns</li>
<li>Send 2K bytes over 1 Gbps network 20,000 ns</li>
<li>Read 1 MB sequentially from memory 250,000 ns</li>
<li>Round trip within same datacenter 500,000 ns</li>
<li>Disk seek 10,000,000 ns</li>
<li>Read 1 MB sequentially from network 10,000,000 ns</li>
<li>Read 1 MB sequentially from disk 30,000,000 ns</li>
<li>Send packet CA-&gt;Netherlands-&gt;CA 150,000,000 ns</li>
</ul>
<p>And here is an updated, interactive <a href="https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html">version</a>, which includes a timeline of how these numbers have changed.</p>
<p><strong>Key take-away</strong>: Each successive memory type is (at least) an order of magnitude worse than the one before it.  Disk seeks are <strong>very slow</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This video has a great example of showing several ways you could compute the blur of a photo, with various trade-offs. Don't worry about the C code that appears, just focus on the red and green moving pictures of matrix computation.</p>
<p>Although the video is about a new language called Halide, it is a good illustration the issues it raises are universal.  Watch minutes 1-13:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s2">&quot;3uiEyEKji0M&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

        <iframe
            width="400"
            height="300"
            src="https://www.youtube.com/embed/3uiEyEKji0M"
            frameborder="0"
            allowfullscreen
        ></iframe>
        
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Locality is hard.  Potential trade-offs:</p>
<ul>
<li>redundant computation to save memory bandwidth</li>
<li>sacrificing parallelism to get better reuse</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Temporaries">Temporaries<a class="anchor-link" href="#Temporaries">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The issue of "temporaries" occurs when the result of a calculation is stored in a temporary variable in RAM, and then that variable is loaded to do another calculation on it. This is many orders of magnitude slower than simply keeping the data in cache or registers and doing all necessary computations before storing the final result in RAM. This is particularly an issue for us since numpy generally creates temporaries for every single operation or function it does. E.g. $a=b\cdot c^2+ln(d)$ will create four temporaries (since there are four operations and functions).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Scaling-to-multiple-cores-and-nodes">Scaling to multiple cores and nodes<a class="anchor-link" href="#Scaling-to-multiple-cores-and-nodes">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We have a separate section for scalability, but it’s worth noting that this is also important for speed - if we can't scale across all the computing resources we have, we'll be stuck with slower computation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Scalability-/-parallelization">Scalability / parallelization<a class="anchor-link" href="#Scalability-/-parallelization">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Often we'll find that we have more data than we have memory to handle, or time to compute. In such a case we would like to be able to scale our algorithm across <a href="http://www.makeuseof.com/tag/processor-core-makeuseof-explains-2/">multiple cores</a> (within one computer) or nodes (i.e. multiple computers on a network). We will not be tackling multi-node scaling in this course, although we will look at scaling across multiple cores (called parallelization). In general, scalable algorithms are those where the input can be broken up into smaller pieces, each of which are handled by a different core/computer, and then are put back together at the end.</p>

</div>
</div>
</div>
</div>
 

